library(readr)
data <- read_csv("C:/Users/Tripti Tanvi/Desktop/data.csv")
View(data)
library(readr)
list <- read_csv("C:/Users/Tripti Tanvi/Desktop/list.csv")
View(list)
write.csv(df_itemList,"list.csv", row.names = TRUE)
#Implementing Market Basket Analysis using Apriori Algorithm
#read transactions
df_groceries <- read.csv("data.csv")
str(df_groceries)
df_sorted <- df_groceries[order(df_groceries$Member_number),]
#convert member number to numeric
df_sorted$Member_number <- as.numeric(df_sorted$Member_number)
#convert item description to categorical format
df_sorted$itemDescription <- as.factor(df_sorted$itemDescription)
str(df_sorted)
#convert dataframe to transaction format using ddply;
if(sessionInfo()['basePkgs']=="dplyr" | sessionInfo()['otherPkgs']=="dplyr"){
detach(package:dplyr, unload=TRUE)
}
#group all the items that were bought together; by the same customer on the same date
library(plyr)
df_itemList <- ddply(df_groceries, c("Member_number","Date"), function(df1)paste(df1$itemDescription,collapse = ","))
#remove member number and date
df_itemList$Member_number <- NULL
df_itemList$Date <- NULL
colnames(df_itemList) <- c("itemList")
#write to csv format
write.csv(df_itemList,"list.csv", row.names = TRUE)
#-------------------- association rule mining algorithm : apriori -------------------------#
#load package required
library(arules)
#convert csv file to basket format
txn = read.transactions(file="ItemList.csv", rm.duplicates= TRUE, format="basket",sep=",",cols=1);
#remove quotes from transactions
txn@itemInfo$labels <- gsub("\"","",txn@itemInfo$labels)
#run apriori algorithm
basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.01, conf = 0.1, target="rules"))
#basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.00001, conf = 0.01, target="rules"),appearance = list(lhs = "CLEMENTINES")))
#check if tm is attched; if yes then detach
if(sessionInfo()['basePkgs']=="tm" | sessionInfo()['otherPkgs']=="tm"){
detach(package:sentiment, unload=TRUE)
detach(package:tm, unload=TRUE)
}
#view rules
inspect(basket_rules)
#convert to datframe and view; optional
df_basket <- as(basket_rules,"data.frame")
df_basket$confidence <- df_basket$confidence * 100
df_basket$support <- df_basket$support * nrow(df)
write.csv(df_basket,"Rules_20.csv",row.names = FALSE)
#plot the rules
library(arulesViz)
plot(basket_rules)
set.seed(8000)
plot(basket_rules, method = "grouped", control = list(k = 5))
plot(basket_rules[1:10,], method="graph", control=list(type="items"))
plot(basket_rules[1:10,], method="paracoord",  control=list(alpha=.5, reorder=TRUE))
itemFrequencyPlot(txn, topN = 5)
plot(basket_rules[1:10,],measure=c("support","lift"),shading="confidence",interactive=T)
#Implementing Market Basket Analysis using Apriori Algorithm
#read transactions
df_groceries <- read.csv("data.csv")
str(df_groceries)
df_sorted <- df_groceries[order(df_groceries$Member_number),]
#convert member number to numeric
df_sorted$Member_number <- as.numeric(df_sorted$Member_number)
#convert item description to categorical format
df_sorted$itemDescription <- as.factor(df_sorted$itemDescription)
str(df_sorted)
#convert dataframe to transaction format using ddply;
if(sessionInfo()['basePkgs']=="dplyr" | sessionInfo()['otherPkgs']=="dplyr"){
detach(package:dplyr, unload=TRUE)
}
#group all the items that were bought together; by the same customer on the same date
library(plyr)
df_itemList <- ddply(df_groceries, c("Member_number","Date"), function(df1)paste(df1$itemDescription,collapse = ","))
#remove member number and date
df_itemList$Member_number <- NULL
df_itemList$Date <- NULL
colnames(df_itemList) <- c("itemList")
#write to csv format
write.csv(df_itemList,"list.csv", row.names = TRUE)
#-------------------- association rule mining algorithm : apriori -------------------------#
#load package required
library(arules)
#convert csv file to basket format
txn = read.transactions(file="list.csv", rm.duplicates= TRUE, format="basket",sep=",",cols=1);
#remove quotes from transactions
txn@itemInfo$labels <- gsub("\"","",txn@itemInfo$labels)
#run apriori algorithm
basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.01, conf = 0.1, target="rules"))
#basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.00001, conf = 0.01, target="rules"),appearance = list(lhs = "CLEMENTINES")))
#check if tm is attched; if yes then detach
if(sessionInfo()['basePkgs']=="tm" | sessionInfo()['otherPkgs']=="tm"){
detach(package:sentiment, unload=TRUE)
detach(package:tm, unload=TRUE)
}
#view rules
inspect(basket_rules)
#convert to datframe and view; optional
df_basket <- as(basket_rules,"data.frame")
df_basket$confidence <- df_basket$confidence * 100
df_basket$support <- df_basket$support * nrow(df)
write.csv(df_basket,"Rules_20.csv",row.names = FALSE)
#plot the rules
library(arulesViz)
plot(basket_rules)
set.seed(8000)
plot(basket_rules, method = "grouped", control = list(k = 5))
plot(basket_rules[1:10,], method="graph", control=list(type="items"))
plot(basket_rules[1:10,], method="paracoord",  control=list(alpha=.5, reorder=TRUE))
itemFrequencyPlot(txn, topN = 5)
plot(basket_rules[1:10,],measure=c("support","lift"),shading="confidence",interactive=T)
View(list)
View(list)
library("tibble", lib.loc="~/R/win-library/3.3")
library("readr", lib.loc="~/R/win-library/3.3")
library("Rcpp", lib.loc="~/R/win-library/3.3")
library("hms", lib.loc="~/R/win-library/3.3")
library("R6", lib.loc="~/R/win-library/3.3")
library("lazyeval", lib.loc="~/R/win-library/3.3")
library("curl", lib.loc="~/R/win-library/3.3")
library("assertthat", lib.loc="~/R/win-library/3.3")
library("boot", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("cluster", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("class", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("codetools", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("compiler", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("datasets", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("foreign", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("grDevices", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("graphics", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("stats", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("splines", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("spatial", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("rpart", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("parallel", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("nnet", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("nlme", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("mgcv", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("methods", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("MASS", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("Matrix", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("lattice", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("KernSmooth", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("grid", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("translations", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("utils", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("tools", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("tcltk", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("survival", lib.loc="C:/Program Files/R/R-3.3.2/library")
library("stats4", lib.loc="C:/Program Files/R/R-3.3.2/library")
install.packages("arules")
library("arules", lib.loc="~/R/win-library/3.3")
detach("package:arules", unload=TRUE)
#Implementing Market Basket Analysis using Apriori Algorithm
#read transactions
df_groceries <- read.csv("data.csv")
str(df_groceries)
df_sorted <- df_groceries[order(df_groceries$Member_number),]
#convert member number to numeric
df_sorted$Member_number <- as.numeric(df_sorted$Member_number)
#convert item description to categorical format
df_sorted$itemDescription <- as.factor(df_sorted$itemDescription)
str(df_sorted)
#convert dataframe to transaction format using ddply;
if(sessionInfo()['basePkgs']=="dplyr" | sessionInfo()['otherPkgs']=="dplyr"){
detach(package:dplyr, unload=TRUE)
}
#group all the items that were bought together; by the same customer on the same date
library(plyr)
df_itemList <- ddply(df_groceries, c("Member_number","Date"), function(df1)paste(df1$itemDescription,collapse = ","))
#remove member number and date
df_itemList$Member_number <- NULL
df_itemList$Date <- NULL
colnames(df_itemList) <- c("itemList")
#write to csv format
write.csv(df_itemList,"list.csv", row.names = TRUE)
#-------------------- association rule mining algorithm : apriori -------------------------#
#load package required
library(arules)
#convert csv file to basket format
txn = read.transactions(file="list.csv", rm.duplicates= TRUE, format="basket",sep=",",cols=1);
#remove quotes from transactions
txn@itemInfo$labels <- gsub("\"","",txn@itemInfo$labels)
#run apriori algorithm
basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.01, conf = 0.1, target="rules"))
#basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.00001, conf = 0.01, target="rules"),appearance = list(lhs = "CLEMENTINES")))
#check if tm is attched; if yes then detach
if(sessionInfo()['basePkgs']=="tm" | sessionInfo()['otherPkgs']=="tm"){
detach(package:sentiment, unload=TRUE)
detach(package:tm, unload=TRUE)
}
#view rules
inspect(basket_rules)
#convert to datframe and view; optional
df_basket <- as(basket_rules,"data.frame")
df_basket$confidence <- df_basket$confidence * 100
df_basket$support <- df_basket$support * nrow(df)
write.csv(df_basket,"Rules_20.csv",row.names = FALSE)
#plot the rules
library(arulesViz)
plot(basket_rules)
set.seed(8000)
plot(basket_rules, method = "grouped", control = list(k = 5))
plot(basket_rules[1:10,], method="graph", control=list(type="items"))
plot(basket_rules[1:10,], method="paracoord",  control=list(alpha=.5, reorder=TRUE))
itemFrequencyPlot(txn, topN = 5)
plot(basket_rules[1:10,],measure=c("support","lift"),shading="confidence",interactive=T)
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
processed <- processed[,-1]
library(rpart)
library(rpart.plot)
library(randomForest)
library(pROC)
library(vcd)
c_data <- read.csv("titanic.csv")
c_data <- c_data[,-1]
c_data$Survived <- factor(c_data$Survived)
#logistic regression
logit <- glm(Survived~.,data=c_data,family=binomial(logit))
roc(c_data$Survived,round(predict(logit)),plot=T,col="#006699",main="ROC curve")
mtext("Area under the curve: 0.8684",side=3)
#classification tree
model0 <- rpart(Survived~.,data=c_data,method="class")
table(c_data$Survived,round(predict(model0,method="response")))
prp(model0,extra=1,type=3,cex=1.2,main="Classification Tree for Titanic Survive",under.col="#006699",split.col="#999999",compress=T,under=TRUE,under.cex=0.6,split.cex=0.5)
#random Forest Tree
c_data$Survived <- factor(c_data$Survived)
model1 <- randomForest(Survived~.,data=c_data,prox=T)
model1
importance(model1)
# The mean decrease in Gini coefficient is a measure of how each variable contributes to the homogeneity of the nodes and leaves in the resulting random forest.
#http://dinsdalelab.sdsu.edu/metag.stats/code/randomforest.html (for refernce)
#advanced graph
processed <- read.csv("processed_titanic.csv")
processed <- processed[,-1]
install.packages("rpart.plot")
install.packages("pROC")
install.packages("vcd")
library(rpart)
library(rpart.plot)
library(randomForest)
library(pROC)
library(vcd)
c_data <- read.csv("titanic.csv")
c_data <- c_data[,-1]
c_data$Survived <- factor(c_data$Survived)
#logistic regression
logit <- glm(Survived~.,data=c_data,family=binomial(logit))
roc(c_data$Survived,round(predict(logit)),plot=T,col="#006699",main="ROC curve")
mtext("Area under the curve: 0.8684",side=3)
#classification tree
model0 <- rpart(Survived~.,data=c_data,method="class")
table(c_data$Survived,round(predict(model0,method="response")))
prp(model0,extra=1,type=3,cex=1.2,main="Classification Tree for Titanic Survive",under.col="#006699",split.col="#999999",compress=T,under=TRUE,under.cex=0.6,split.cex=0.5)
#random Forest Tree
c_data$Survived <- factor(c_data$Survived)
model1 <- randomForest(Survived~.,data=c_data,prox=T)
model1
importance(model1)
# The mean decrease in Gini coefficient is a measure of how each variable contributes to the homogeneity of the nodes and leaves in the resulting random forest.
#http://dinsdalelab.sdsu.edu/metag.stats/code/randomforest.html (for refernce)
#advanced graph
processed <- read.csv("processed_titanic.csv")
processed <- processed[,-1]
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
install.packages("randomForest")
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
library(readr)
processed_titanic <- read_csv("C:/Users/Tripti Tanvi/Desktop/processed_titanic.csv")
View(processed_titanic)
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
library(readr)
titanic <- read_csv("C:/Users/Tripti Tanvi/Downloads/titanic.csv")
View(titanic)
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
setwd("C:/Users/Tripti Tanvi/Desktop")
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
library("vcd", lib.loc="~/R/win-library/3.3")
source('C:/Users/Tripti Tanvi/Desktop/titanic.r')
source('C:/Users/Tripti Tanvi/Desktop/market.r')
install.packages("arulesViz")
source('C:/Users/Tripti Tanvi/Desktop/market.r')
View(c_data)
View(c_data)
summary(rules)
View(df_groceries)
View(df_groceries)
View(processed_titanic)
View(df_sorted)
View(df_itemList)
View(df_basket)
source('C:/Users/Tripti Tanvi/Desktop/market2.R')
source('C:/Users/Tripti Tanvi/Desktop/market2.R')
summary()
summary(info)
source('C:/Users/Tripti Tanvi/Desktop/market2.R')
setwd("C:/Users/Tripti Tanvi/Desktop/data mining project")
View(c_data)
library(readr)
groceries <- read_csv("C:/Users/Tripti Tanvi/Desktop/data mining project/groceries.csv")
View(groceries)
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
tree$whole milk
summary(market2)
summary(tree)
summary(groceries)
summary(lhs)
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
install.packages("plotrix")
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
dev.off()
source('C:/Users/Tripti Tanvi/Desktop/data mining project/market2.R')
